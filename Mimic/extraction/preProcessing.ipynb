{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ca5d9e-3bdd-4b6f-bad9-8860edb21f29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3264f994-4352-475e-a138-71d08515eb56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gestionDonneesAberrantes(dataGroup, variableStr, minTheorique, maxTheorique, columnStr):\n",
    "    \n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath = dataPath + \"rawData/\" + encounterId + \"/\" + variableStr + \".csv\"\n",
    "        df = pd.read_csv(dfPath)\n",
    "        \n",
    "        df_filtered_nan = df[~pd.isna(df[columnStr])]\n",
    "\n",
    "        df_filtered = df_filtered_nan[(df_filtered_nan[columnStr] >= minTheorique) & (df_filtered_nan[columnStr] <= maxTheorique)]\n",
    "\n",
    "        newDfPath = dataPath + \"preProcessedData/\" + encounterId + \"/\" + variableStr + \".parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(df_filtered), newDfPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf5fddc7-e58c-4ef0-8082-c54aa090fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gestionCompliance():\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "    \n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles1.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "    c = 0\n",
    "    for _, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        df_PEP_Path = preProcessedDataPath + encounterId + \"/PEP.parquet\"\n",
    "        df_Pplat_Path = preProcessedDataPath + encounterId + \"/Pplat.parquet\"\n",
    "        df_VolumeCourant_Path = preProcessedDataPath + encounterId + \"/VolumeCourant.parquet\"\n",
    "\n",
    "        df_PEP = pd.read_parquet(df_PEP_Path)\n",
    "        df_Pplat = pd.read_parquet(df_Pplat_Path)\n",
    "        df_VolumeCourant = pd.read_parquet(df_VolumeCourant_Path)\n",
    "        \n",
    "        installation_date = pd.Timestamp(row[\"start_vent\"])\n",
    "        withdrawal_date = installation_date + pd.Timedelta(days=row[\"vent_lenght\"])\n",
    "        total_time_hour = (withdrawal_date - installation_date).total_seconds() / 3600 + 4\n",
    "\n",
    "        liste_valeurs = []\n",
    "        liste_temps = []        \n",
    "        \n",
    "        for i in range(int(total_time_hour)):\n",
    "\n",
    "            current_time_minute = i*60\n",
    "            \n",
    "            VolumeCourant_current_values = df_VolumeCourant[df_VolumeCourant[\"time\"]==current_time_minute]\n",
    "            Pplat_current_values = df_Pplat[df_Pplat[\"time\"]==current_time_minute]\n",
    "            PEP_current_values = df_PEP[df_PEP[\"time\"]==current_time_minute]\n",
    "\n",
    "            if VolumeCourant_current_values.size > 0 and Pplat_current_values.size > 0 and PEP_current_values.size > 0:\n",
    "                \n",
    "                volumeCourant = VolumeCourant_current_values[\"VolumeCourant\"].iloc[0]\n",
    "                Pplat = Pplat_current_values[\"Pplat\"].iloc[0]\n",
    "                PEP = PEP_current_values[\"PEP\"].iloc[0]\n",
    "                \n",
    "                compliance = volumeCourant / (Pplat - PEP)\n",
    "                # print(f\"VC: {volumeCourant}, Pplat: {Pplat} with {prio}, PEP: {PEP}, Compliance: {compliance}\")\n",
    "\n",
    "                if compliance > 0 and compliance < 150:\n",
    "                    liste_valeurs.append(compliance)\n",
    "                    liste_temps.append(current_time_minute)\n",
    "        \n",
    "        # if c==13:\n",
    "        #     return liste_valeurs, liste_temps\n",
    "        # c+=1\n",
    "        newdf = pd.DataFrame({'Compliance': liste_valeurs, 'temps': liste_temps})\n",
    "        newdfPath = preProcessedDataPath + encounterId + \"/Compliance_Moy.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newdfPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d177193a-b8ba-41b4-bca9-7791bc61bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                                                                                           | 26/4657 [00:04<16:15,  4.75it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      "  6%|████████▋                                                                                                                                                  | 261/4657 [00:43<12:58,  5.64it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      "  9%|█████████████▌                                                                                                                                             | 409/4657 [01:09<10:14,  6.91it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 13%|████████████████████▎                                                                                                                                      | 610/4657 [01:44<11:57,  5.64it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 27%|█████████████████████████████████████████▍                                                                                                                | 1254/4657 [03:38<14:49,  3.83it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 28%|███████████████████████████████████████████▋                                                                                                              | 1321/4657 [03:49<07:10,  7.75it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 30%|██████████████████████████████████████████████▏                                                                                                           | 1397/4657 [04:04<09:23,  5.78it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 32%|█████████████████████████████████████████████████▉                                                                                                        | 1510/4657 [04:22<08:55,  5.88it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 33%|███████████████████████████████████████████████████▌                                                                                                      | 1560/4657 [04:31<09:46,  5.28it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 34%|█████████████████████████████████████████████████████                                                                                                     | 1604/4657 [04:39<06:59,  7.29it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 43%|█████████████████████████████████████████████████████████████████▌                                                                                        | 1981/4657 [05:45<16:10,  2.76it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 48%|██████████████████████████████████████████████████████████████████████████▏                                                                               | 2242/4657 [06:31<06:32,  6.16it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████▊                                                                            | 2352/4657 [06:50<05:31,  6.95it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 52%|████████████████████████████████████████████████████████████████████████████████▍                                                                         | 2434/4657 [07:05<05:13,  7.09it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 2841/4657 [08:20<05:23,  5.61it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 2879/4657 [08:27<06:37,  4.48it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                  | 3119/4657 [09:12<03:56,  6.50it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 3832/4657 [11:19<02:45,  4.97it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4020/4657 [11:54<01:46,  6.00it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 4088/4657 [12:06<01:28,  6.40it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍              | 4215/4657 [12:26<01:13,  6.05it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 4479/4657 [13:14<00:23,  7.49it/s]/tmp/ipykernel_124169/4157913798.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  compliance = volumeCourant / (Pplat - PEP)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4657/4657 [13:47<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "gestionCompliance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9793f0fe-d549-4092-b7a0-1170c8428094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gestionDiurese():\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "    \n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles1.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    rawDataPath = dataPath + \"rawData/\"\n",
    "    \n",
    "    nb_patients = len(patients_df)\n",
    "    c = 0\n",
    "    for _, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        df_Dialyse_Path = rawDataPath + encounterId + \"/dialyse.csv\"\n",
    "\n",
    "        list_Dialyse = pd.read_csv(df_Dialyse_Path).to_numpy().tolist()\n",
    "\n",
    "        installation_date = pd.Timestamp(row[\"start_vent\"])\n",
    "        withdrawal_date = installation_date + pd.Timedelta(days=row[\"vent_lenght\"])\n",
    "        total_time_hour = (withdrawal_date - installation_date).total_seconds() / 3600 + 4\n",
    "        \n",
    "        liste_valeurs = [0] * int(total_time_hour)\n",
    "        \n",
    "        for e in list_Dialyse:\n",
    "            \n",
    "            temps = e[0]\n",
    "            current_time_hour = (temps+30)//60\n",
    "\n",
    "            if current_time_hour+1 < int(total_time_hour) and current_time_hour > 0:\n",
    "                liste_valeurs[current_time_hour] = 1\n",
    "                liste_valeurs[current_time_hour+1] = 1\n",
    "    \n",
    "            \n",
    "        newdf = pd.DataFrame({'Dialyse': liste_valeurs})\n",
    "        newdfPath = preProcessedDataPath + encounterId + \"/Dialyse_Complet.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newdfPath)\n",
    "\n",
    "        newdf = pd.DataFrame({'Dialyse': np.array(liste_valeurs)*0+1})\n",
    "        newdfPath = preProcessedDataPath + encounterId + \"/Dialyse_Mask.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newdfPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687a7d81-1423-49f0-80b2-41c58377a6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4657/4657 [00:07<00:00, 604.83it/s]\n"
     ]
    }
   ],
   "source": [
    "gestionDiurese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739d9d5d-4944-4dff-85d7-5e542873d2f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gestionPoids(dataGroup):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "    \n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath = preProcessedDataPath + encounterId + \"/Weight.parquet\"\n",
    "        \n",
    "        df = pd.read_parquet(dfPath)\n",
    "        \n",
    "        numeric_values = pd.to_numeric(df.iloc[:, 0], errors='coerce').dropna()\n",
    "\n",
    "        if df.size == 0:\n",
    "            meanWeight = 80.0001\n",
    "        else:\n",
    "            meanWeight = np.mean(numeric_values)\n",
    "\n",
    "        newdf = pd.DataFrame([meanWeight])\n",
    "\n",
    "        newDfPath = preProcessedDataPath + encounterId + \"/Weight3.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "\n",
    "def gestionTaille(dataGroup):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath = preProcessedDataPath + encounterId + \"/Height.parquet\"\n",
    "\n",
    "        df = pd.read_parquet(dfPath)\n",
    "        \n",
    "        numeric_values = pd.to_numeric(df.iloc[:, 0], errors='coerce').dropna()\n",
    "\n",
    "        if df.size == 0:\n",
    "            meanHeight = 171.0001\n",
    "        else:\n",
    "            meanHeight = np.mean(numeric_values)\n",
    "        \n",
    "        newdf = pd.DataFrame([meanHeight])\n",
    "\n",
    "        newDfPath = preProcessedDataPath + encounterId + \"/Height_Moy.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "\n",
    "def gestionIMC(dataGroup):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    gestionPoids(dataGroup)\n",
    "    gestionTaille(dataGroup)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath_height = preProcessedDataPath + encounterId + \"/Height_Moy.parquet\"\n",
    "        height = pd.read_parquet(dfPath_height).iloc[0][0]\n",
    "\n",
    "        dfPath_weight = preProcessedDataPath + encounterId + \"/Weight3.parquet\"\n",
    "        weight = pd.read_parquet(dfPath_weight).iloc[0][0]\n",
    "\n",
    "        imc = weight / ((height/100)**2)\n",
    "\n",
    "        newdf = pd.DataFrame([imc])\n",
    "        newDfPath = preProcessedDataPath + encounterId + \"/IMC.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "\n",
    "def gestionDiurese(dataGroup, h_for_avg):\n",
    "    \n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath = preProcessedDataPath + encounterId + \"/Diurese.parquet\"\n",
    "        \n",
    "        df = pd.read_parquet(dfPath)\n",
    "        \n",
    "        weight = pd.read_parquet(preProcessedDataPath+encounterId+\"/Weight3.parquet\").to_numpy()[0][0]\n",
    "\n",
    "        liste_diurese_moy = []\n",
    "        liste_temps = []\n",
    "        \n",
    "        for i in range(h_for_avg,df['time'].size):\n",
    "            temps_i = df['time'].iloc[i]\n",
    "            valide = True\n",
    "            diurese_moy = 0\n",
    "            for j in range(h_for_avg):\n",
    "                if df['time'].iloc[i-j] == (temps_i - 60*j):\n",
    "                    diurese_moy += df['Diurese'].iloc[i-j]\n",
    "                else:\n",
    "                    valide = False\n",
    "                    break\n",
    "            diurese_moy = diurese_moy/h_for_avg/weight\n",
    "            if valide and temps_i > -h_for_avg*60:\n",
    "                liste_diurese_moy.append(diurese_moy)\n",
    "                liste_temps.append(temps_i)\n",
    "\n",
    "        newdf = pd.DataFrame({'Diurese': liste_diurese_moy, 'time': liste_temps})\n",
    "\n",
    "        newDfPath = preProcessedDataPath + encounterId + \"/Diurese0.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "\n",
    "def gestionFiO2(dataGroup, frequenceAcquisition):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    columnValuesStr_FiO2 = 'FiO2'\n",
    "    columnValuesStr_SpO2 = 'SpO2'\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath_FiO2 = preProcessedDataPath + encounterId + \"/FiO2.parquet\"\n",
    "        dfPath_SpO2 = preProcessedDataPath + encounterId + \"/SpO2_Moy.parquet\"\n",
    "\n",
    "        df_FiO2 = pd.read_parquet(dfPath_FiO2)\n",
    "        df_SpO2 = pd.read_parquet(dfPath_SpO2)\n",
    "\n",
    "        sizeDf_FiO2 = df_FiO2[columnValuesStr_FiO2].size\n",
    "        sizeDf_SpO2 = df_SpO2[columnValuesStr_SpO2].size\n",
    "        new_index = range(sizeDf_FiO2)\n",
    "        df_FiO2.index = new_index\n",
    "\n",
    "        liste_valeurs = []\n",
    "        \n",
    "        # Test si le df est vide\n",
    "        if sizeDf_FiO2 > 0:\n",
    "            lastTime = int(df_FiO2['time'].iloc[-1] // frequenceAcquisition)\n",
    "        else:\n",
    "            lastTime = 0\n",
    "\n",
    "        nbValeurs = df_FiO2.index.max()+1\n",
    "\n",
    "        # On calcule la valeur moyenne de la variable d'intérêt sur un intervalle de temps donné en paramètre\n",
    "        index_current_time = 0\n",
    "        for i in range(lastTime):\n",
    "            FiO2_sum = 0\n",
    "            current_time = df_FiO2['time'][index_current_time]\n",
    "            compteur = 0\n",
    "\n",
    "            while (current_time < 0):\n",
    "                index_current_time += 1\n",
    "                current_time = df_FiO2['time'][index_current_time]\n",
    "            \n",
    "            while (current_time < (i+1)*frequenceAcquisition) and (index_current_time < nbValeurs):\n",
    "                FiO2_sum += df_FiO2[columnValuesStr_FiO2][index_current_time] \n",
    "\n",
    "                index_current_time += 1\n",
    "                current_time = df_FiO2['time'][index_current_time]\n",
    "                compteur += 1\n",
    "            \n",
    "            if compteur > 0:\n",
    "                FiO2_moy = FiO2_sum/compteur\n",
    "                if i<sizeDf_SpO2 and not(np.isnan(df_SpO2[columnValuesStr_SpO2][i])):\n",
    "                    liste_valeurs.append(df_SpO2[columnValuesStr_SpO2][i]/FiO2_moy)\n",
    "                else:\n",
    "                    liste_valeurs.append(np.nan)\n",
    "            else:\n",
    "                liste_valeurs.append(np.nan)\n",
    "\n",
    "        \n",
    "        liste_temps = list(range(0,lastTime*frequenceAcquisition,frequenceAcquisition))\n",
    "\n",
    "        newdf = pd.DataFrame({'SpO2_sur_FiO2': liste_valeurs, 'temps': liste_temps})\n",
    "\n",
    "        newDfPath = preProcessedDataPath + encounterId + \"/SpO2_sur_FiO2_Moy.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "\n",
    "def moyenne_sur_x_minutes(dataGroup, variableStr, frequenceAcquisition, columnValuesStr):\n",
    "    \n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        dfPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \".parquet\"\n",
    "        \n",
    "        df = pd.read_parquet(dfPath)\n",
    "\n",
    "        sizeDf = df[columnValuesStr].size\n",
    "        new_index = range(sizeDf)\n",
    "        df.index = new_index\n",
    "\n",
    "        liste_valeurs = []\n",
    "        \n",
    "        # Test si le df est vide\n",
    "        if sizeDf > 0:\n",
    "            lastTime = int(df['time'].iloc[-1] // frequenceAcquisition)\n",
    "        else:\n",
    "            lastTime = 0\n",
    "\n",
    "        nbValeurs = df.index.max()+1\n",
    "\n",
    "        # On calcule la valeur moyenne de la variable d'intérêt sur un intervalle de temps donné en paramètre\n",
    "        index_current_time = 0\n",
    "        for i in range(lastTime):\n",
    "            valeur_moy = 0\n",
    "            current_time = df['time'][index_current_time]\n",
    "            compteur = 0\n",
    "            \n",
    "            while (current_time < 0):\n",
    "                index_current_time += 1\n",
    "                current_time = df['time'][index_current_time]\n",
    "                \n",
    "            while (current_time < (i+1)*frequenceAcquisition) and (index_current_time < nbValeurs):\n",
    "                valeur_moy += df[columnValuesStr][index_current_time] \n",
    "\n",
    "                index_current_time += 1\n",
    "                current_time = df['time'][index_current_time]\n",
    "                compteur += 1\n",
    "            \n",
    "            if compteur > 0:\n",
    "                liste_valeurs.append(valeur_moy/compteur)\n",
    "            else:\n",
    "                liste_valeurs.append(np.nan)\n",
    "\n",
    "        \n",
    "        liste_temps = list(range(0,lastTime*frequenceAcquisition,frequenceAcquisition))\n",
    "\n",
    "        newdf = pd.DataFrame({columnValuesStr: liste_valeurs, 'temps': liste_temps})\n",
    "\n",
    "        newDfPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Moy.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(newdf), newDfPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dde738-4e69-40c8-a008-72612fc2cce3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gestionValeursManquantes(dataGroup, variableStr, columnValuesStr, defaultValue, isDiurese=False):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles1.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "            encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "            dfPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Moy\" + \".parquet\"\n",
    "            \n",
    "            df = pd.read_parquet(dfPath)\n",
    "\n",
    "            sizeDf = df[columnValuesStr].size\n",
    "\n",
    "            # La taille des listes est fixée au nombre d'heures total du séjour (+4) \n",
    "            installation_date = pd.Timestamp(row[\"start_vent\"])\n",
    "            withdrawal_date = installation_date + pd.Timedelta(days=row[\"vent_lenght\"])\n",
    "            total_time_hour = (withdrawal_date - installation_date).total_seconds() / 3600 + 4\n",
    "\n",
    "            liste_valeurs = []\n",
    "            liste_mask = [] # permet de savoir si une valeur est manquante à l'origine\n",
    "            \n",
    "            if df[columnValuesStr].isnull().all() or sizeDf == 0:\n",
    "                liste_valeurs = [defaultValue] * int(total_time_hour)\n",
    "                liste_mask = [0] * int(total_time_hour)\n",
    "                sizeDf = 0\n",
    "            \n",
    "            if sizeDf > 0:\n",
    "                for i in range(int(total_time_hour)):\n",
    "\n",
    "                    if i >= sizeDf: # plus de valeurs existantes à partir de là\n",
    "                        val_i = np.nan\n",
    "                    else:\n",
    "                        val_i = df[columnValuesStr][i]\n",
    "\n",
    "                    if np.isnan(val_i):\n",
    "                        \n",
    "                        liste_mask.append(0) # On crée une valeur qui n'existe pas\n",
    "                        \n",
    "                        j = 1\n",
    "                        found = False\n",
    "                        \n",
    "                        # On associe la valeur la plus proche\n",
    "                        # En cas d'equidistance la moyenne entre les 2 valeurs les plus proches\n",
    "                        while not(found):\n",
    "                            if i-j < 0:\n",
    "                                while i+j < sizeDf:\n",
    "                                    val_i_plus_j = df[columnValuesStr][i+j]\n",
    "                                    if not(np.isnan(val_i_plus_j)):\n",
    "                                        new_val = val_i_plus_j\n",
    "                                        found = True\n",
    "                                        break\n",
    "                                    j += 1\n",
    "                            elif i+j >= sizeDf:\n",
    "                                while i-j >= sizeDf:\n",
    "                                    j += 1\n",
    "                                while i-j >= 0:\n",
    "                                    val_i_moins_j = df[columnValuesStr][i-j]\n",
    "                                    if not(np.isnan(val_i_moins_j)):\n",
    "                                        new_val = val_i_moins_j\n",
    "                                        found = True\n",
    "                                        break\n",
    "                                    j += 1\n",
    "                            else:\n",
    "                                val_i_moins_j = df[columnValuesStr][i-j]\n",
    "                                val_i_plus_j = df[columnValuesStr][i+j]\n",
    "                                if not(np.isnan(val_i_moins_j)):\n",
    "                                    if not(np.isnan(val_i_plus_j)):\n",
    "                                        new_val = (val_i_moins_j + val_i_plus_j) * 0.5\n",
    "                                    else:\n",
    "                                        new_val = val_i_moins_j\n",
    "                                    found = True\n",
    "                                elif not(np.isnan(val_i_plus_j)):\n",
    "                                    new_val = val_i_plus_j\n",
    "                                    found = True\n",
    "                            j += 1\n",
    "                        \n",
    "                        liste_valeurs.append(new_val)\n",
    "\n",
    "                    else:\n",
    "                        liste_mask.append(1) # La valeur existe\n",
    "                        liste_valeurs.append(val_i)\n",
    "            \n",
    "            if isDiurese:\n",
    "                newdf = pd.DataFrame({columnValuesStr: liste_valeurs})\n",
    "                newdfPath = preProcessedDataPath + encounterId + \"/Diurese_Complet.parquet\"\n",
    "                pq.write_table(pa.Table.from_pandas(newdf), newdfPath)\n",
    "    \n",
    "                newdfMask = pd.DataFrame({'mask': liste_mask})\n",
    "                newdfMaskPath = preProcessedDataPath + encounterId + \"/Diurese_Mask.parquet\"\n",
    "                pq.write_table(pa.Table.from_pandas(newdfMask), newdfMaskPath)\n",
    "            else:\n",
    "                newdf = pd.DataFrame({columnValuesStr: liste_valeurs})\n",
    "                newdfPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Complet.parquet\"\n",
    "                pq.write_table(pa.Table.from_pandas(newdf), newdfPath)\n",
    "    \n",
    "                newdfMask = pd.DataFrame({'mask': liste_mask})\n",
    "                newdfMaskPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Mask.parquet\"\n",
    "                pq.write_table(pa.Table.from_pandas(newdfMask), newdfMaskPath)\n",
    "\n",
    "\n",
    "\n",
    "# Fonction à part pour les pressions artérielles\n",
    "# On associe d'abord la PAI si elle existe, sinon la PANI si elle existe, sinon la PAI la plus proche si elle existe, sinon la PANI la plus proche\n",
    "def gestionValeursManquantesPA(dataGroup, PA_Str, columnValuesStr, defaultValue):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    PA_I_Str = PA_Str + \"_I\"\n",
    "    PA_NI_str = PA_Str + \"_NI\"\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "            \n",
    "            columnValuesStr_PAI = columnValuesStr + \"_I\"\n",
    "            columnValuesStr_PANI = columnValuesStr + \"_NI\"\n",
    "\n",
    "            encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "            dfPath = preProcessedDataPath + encounterId + \"/\" + PA_I_Str + \"_Moy\" + \".parquet\"\n",
    "            dfPath2 = preProcessedDataPath + encounterId + \"/\" + PA_NI_str + \"_Moy\" + \".parquet\"\n",
    "\n",
    "            df = pd.read_parquet(dfPath)\n",
    "            df2 = pd.read_parquet(dfPath2)\n",
    "\n",
    "            sizeDf = df[columnValuesStr_PAI].size\n",
    "            sizeDf2 = df2[columnValuesStr_PANI].size\n",
    "\n",
    "            installation_date = pd.Timestamp(row[\"start_vent\"])\n",
    "            withdrawal_date = installation_date + pd.Timedelta(days=row[\"vent_lenght\"])\n",
    "            total_time_hour = (withdrawal_date - installation_date).total_seconds() / 3600 + 4\n",
    "\n",
    "            liste_valeurs = []\n",
    "            liste_mask = [] # permet de savoir si une valeur est manquante à l'origine\n",
    "\n",
    "            if df[columnValuesStr_PAI].isnull().all() or sizeDf == 0:\n",
    "                if df2[columnValuesStr_PANI].isnull().all() or sizeDf2 == 0:\n",
    "                    liste_valeurs = [defaultValue] * int(total_time_hour)\n",
    "                    liste_mask = [0] * int(total_time_hour)\n",
    "                    sizeDf = 0\n",
    "                else:\n",
    "                    df = df2\n",
    "                    columnValuesStr_PAI = columnValuesStr_PANI\n",
    "                    sizeDf = sizeDf2\n",
    "\n",
    "            if sizeDf > 0:\n",
    "                for i in range(int(total_time_hour)):\n",
    "\n",
    "                    if i >= sizeDf:\n",
    "                        val_i = np.nan\n",
    "                    else:\n",
    "                        val_i = df[columnValuesStr_PAI][i]\n",
    "\n",
    "                    if np.isnan(val_i):\n",
    "\n",
    "                        if (i < sizeDf2) and (not(np.isnan(df2[columnValuesStr_PANI][i]))):\n",
    "                            new_val = df2[columnValuesStr_PANI][i]\n",
    "                            liste_valeurs.append(new_val)\n",
    "                            liste_mask.append(1)\n",
    "                        \n",
    "                        else:\n",
    "                            \n",
    "                            liste_mask.append(0)\n",
    "\n",
    "                            j = 1\n",
    "                            found = False\n",
    "                            \n",
    "                            while not(found):\n",
    "                                if i-j < 0:\n",
    "                                    while i+j < sizeDf:\n",
    "                                        val_i_plus_j = df[columnValuesStr_PAI][i+j]\n",
    "                                        if not(np.isnan(val_i_plus_j)):\n",
    "                                            new_val = val_i_plus_j\n",
    "                                            found = True\n",
    "                                            break\n",
    "                                        j += 1\n",
    "                                elif i+j >= sizeDf:\n",
    "                                    while i-j >= sizeDf:\n",
    "                                        j += 1\n",
    "                                    while i-j >= 0:\n",
    "                                        val_i_moins_j = df[columnValuesStr_PAI][i-j]\n",
    "                                        if not(np.isnan(val_i_moins_j)):\n",
    "                                            new_val = val_i_moins_j\n",
    "                                            found = True\n",
    "                                            break\n",
    "                                        j += 1\n",
    "                                else:\n",
    "                                    val_i_moins_j = df[columnValuesStr_PAI][i-j]\n",
    "                                    val_i_plus_j = df[columnValuesStr_PAI][i+j]\n",
    "                                    if not(np.isnan(val_i_moins_j)):\n",
    "                                        if not(np.isnan(val_i_plus_j)):\n",
    "                                            new_val = (val_i_moins_j + val_i_plus_j) * 0.5\n",
    "                                        else:\n",
    "                                            new_val = val_i_moins_j\n",
    "                                        found = True\n",
    "                                    elif not(np.isnan(val_i_plus_j)):\n",
    "                                        new_val = val_i_plus_j\n",
    "                                        found = True\n",
    "                                j += 1\n",
    "                            \n",
    "                            liste_valeurs.append(new_val)\n",
    "\n",
    "                    else:\n",
    "                        liste_mask.append(1)\n",
    "                        liste_valeurs.append(val_i)\n",
    "            \n",
    "\n",
    "            newdf = pd.DataFrame({columnValuesStr: liste_valeurs})\n",
    "            newDfPath = preProcessedDataPath + encounterId + \"/\" + columnValuesStr.upper() + \"_Complet.parquet\"\n",
    "            pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "            newdfMask = pd.DataFrame({'mask': liste_mask})\n",
    "            newdfMaskPath = preProcessedDataPath + encounterId + \"/\" + columnValuesStr.upper() + \"_Mask.parquet\"\n",
    "            pq.write_table(pa.Table.from_pandas(newdfMask), newdfMaskPath)\n",
    "\n",
    "\n",
    "\n",
    "# Fonction à part pour les températures\n",
    "def gestionValeursManquantesTemperatures(columnValuesStr, defaultValue):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles1.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    PA_I_Str = \"Temperature_C\"\n",
    "    PA_NI_str = \"Temperature_F\"\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "            \n",
    "            columnValuesStr_PAI = PA_I_Str\n",
    "            columnValuesStr_PANI = PA_NI_str\n",
    "\n",
    "            encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "            dfPath = preProcessedDataPath + encounterId + \"/\" + PA_I_Str + \"_Moy\" + \".parquet\"\n",
    "            dfPath2 = preProcessedDataPath + encounterId + \"/\" + PA_NI_str + \"_Moy\" + \".parquet\"\n",
    "\n",
    "            df = pd.read_parquet(dfPath)\n",
    "            df2 = (pd.read_parquet(dfPath2) - 32) / 1.8\n",
    "\n",
    "            sizeDf = df[columnValuesStr_PAI].size\n",
    "            sizeDf2 = df2[columnValuesStr_PANI].size\n",
    "\n",
    "            installation_date = pd.Timestamp(row[\"start_vent\"])\n",
    "            withdrawal_date = installation_date + pd.Timedelta(days=row[\"vent_lenght\"])\n",
    "            total_time_hour = (withdrawal_date - installation_date).total_seconds() / 3600 + 4\n",
    "\n",
    "            liste_valeurs = []\n",
    "            liste_mask = [] # permet de savoir si une valeur est manquante à l'origine\n",
    "\n",
    "            if df[columnValuesStr_PAI].isnull().all() or sizeDf == 0:\n",
    "                if df2[columnValuesStr_PANI].isnull().all() or sizeDf2 == 0:\n",
    "                    liste_valeurs = [defaultValue] * int(total_time_hour)\n",
    "                    liste_mask = [0] * int(total_time_hour)\n",
    "                    sizeDf = 0\n",
    "                else:\n",
    "                    df = df2\n",
    "                    columnValuesStr_PAI = columnValuesStr_PANI\n",
    "                    sizeDf = sizeDf2\n",
    "\n",
    "            if sizeDf > 0:\n",
    "                for i in range(int(total_time_hour)):\n",
    "\n",
    "                    if i >= sizeDf:\n",
    "                        val_i = np.nan\n",
    "                    else:\n",
    "                        val_i = df[columnValuesStr_PAI][i]\n",
    "\n",
    "                    if np.isnan(val_i):\n",
    "\n",
    "                        if (i < sizeDf2) and (not(np.isnan(df2[columnValuesStr_PANI][i]))):\n",
    "                            new_val = df2[columnValuesStr_PANI][i]\n",
    "                            liste_valeurs.append(new_val)\n",
    "                            liste_mask.append(1)\n",
    "                        \n",
    "                        else:\n",
    "                            \n",
    "                            liste_mask.append(0)\n",
    "\n",
    "                            j = 1\n",
    "                            found = False\n",
    "                            \n",
    "                            while not(found):\n",
    "                                if i-j < 0:\n",
    "                                    while i+j < sizeDf:\n",
    "                                        val_i_plus_j = df[columnValuesStr_PAI][i+j]\n",
    "                                        if not(np.isnan(val_i_plus_j)):\n",
    "                                            new_val = val_i_plus_j\n",
    "                                            found = True\n",
    "                                            break\n",
    "                                        j += 1\n",
    "                                elif i+j >= sizeDf:\n",
    "                                    while i-j >= sizeDf:\n",
    "                                        j += 1\n",
    "                                    while i-j >= 0:\n",
    "                                        val_i_moins_j = df[columnValuesStr_PAI][i-j]\n",
    "                                        if not(np.isnan(val_i_moins_j)):\n",
    "                                            new_val = val_i_moins_j\n",
    "                                            found = True\n",
    "                                            break\n",
    "                                        j += 1\n",
    "                                else:\n",
    "                                    val_i_moins_j = df[columnValuesStr_PAI][i-j]\n",
    "                                    val_i_plus_j = df[columnValuesStr_PAI][i+j]\n",
    "                                    if not(np.isnan(val_i_moins_j)):\n",
    "                                        if not(np.isnan(val_i_plus_j)):\n",
    "                                            new_val = (val_i_moins_j + val_i_plus_j) * 0.5\n",
    "                                        else:\n",
    "                                            new_val = val_i_moins_j\n",
    "                                        found = True\n",
    "                                    elif not(np.isnan(val_i_plus_j)):\n",
    "                                        new_val = val_i_plus_j\n",
    "                                        found = True\n",
    "                                j += 1\n",
    "                            \n",
    "                            liste_valeurs.append(new_val)\n",
    "\n",
    "                    else:\n",
    "                        liste_mask.append(1)\n",
    "                        liste_valeurs.append(val_i)\n",
    "            \n",
    "\n",
    "            newdf = pd.DataFrame({columnValuesStr: liste_valeurs})\n",
    "            newDfPath = preProcessedDataPath + encounterId + \"/\" + columnValuesStr + \"_Complet.parquet\"\n",
    "            pq.write_table(pa.Table.from_pandas(newdf), newDfPath)\n",
    "\n",
    "            newdfMask = pd.DataFrame({'mask': liste_mask})\n",
    "            newdfMaskPath = preProcessedDataPath + encounterId + \"/\" + columnValuesStr + \"_Mask.parquet\"\n",
    "            pq.write_table(pa.Table.from_pandas(newdfMask), newdfMaskPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713f6a56-929a-4d48-aebe-6e663b9c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allValues(variableStr, dataPath, preProcessedDataPath, patients_df):\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "    \n",
    "    arrayList = []\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "        dfPath = dataPath + preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Moy.parquet\"\n",
    "        df = pd.read_parquet(dfPath)\n",
    "        values = df.to_numpy()[:,0]\n",
    "        arrayList.append(values)\n",
    "\n",
    "    tabValues = np.concatenate(arrayList)\n",
    "\n",
    "    return tabValues\n",
    "\n",
    "def exportStats(dataGroup):\n",
    "\n",
    "    dataPath = \"../dataMimic/\"\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    rawDataPath = \"rawData/\"\n",
    "    preProcessedDataPath = \"preProcessedData/\"\n",
    "\n",
    "    if dataGroup == \"dataECMO\":\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD_I\", \"PAM_I\", \"PAS_I\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"DebitECMO\"]\n",
    "    else:\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD_I\", \"PAM_I\", \"PAS_I\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\"]\n",
    "    \n",
    "    df_stats = pd.DataFrame()\n",
    "    \n",
    "    for variableStr in listeVar:\n",
    "        if variableStr==\"Temperature\":\n",
    "            variableStr = \"Temperature_C\"\n",
    "            values = allValues(variableStr, dataPath, preProcessedDataPath, patients_df)\n",
    "            variableStr = \"Temperature\"\n",
    "        else:\n",
    "            values = allValues(variableStr, dataPath, preProcessedDataPath, patients_df)\n",
    "        mean = np.nanmean(values)\n",
    "        sd = np.nanstd(values)\n",
    "        mini = np.nanmin(values)\n",
    "        maxi = np.nanmax(values)\n",
    "\n",
    "        if variableStr.endswith(\"_I\"):\n",
    "            variableStr = variableStr[:-2]\n",
    "\n",
    "        stat = pd.DataFrame({variableStr: [mean, sd, mini, maxi]})\n",
    "        \n",
    "        df_stats[variableStr] = stat.iloc[:, 0]\n",
    "\n",
    "    df_stats_Path = dataPath + \"stats.parquet\"\n",
    "    pq.write_table(pa.Table.from_pandas(df_stats), df_stats_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ad93bbf-8a73-4e3b-bd23-01eb79a7fbcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def regroupement(dataGroup):\n",
    "\n",
    "    if dataGroup == \"dataECMO\":\n",
    "        dataPath = \"dataECMO/\"\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD\", \"PAM\", \"PAS\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"Compliance\", \"DebitECMO\"]    \n",
    "    elif dataGroup == \"dataRea\":\n",
    "        dataPath = \"dataRea/\"\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD\", \"PAM\", \"PAS\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"Compliance\"]\n",
    "    else:\n",
    "        dataPath = \"../dataMimic/\"\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD\", \"PAM\", \"PAS\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"Compliance\", \"Dialyse\"]\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "    \n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    finalDataPath = dataPath + \"finalData/\"\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "    \n",
    "    df_stats_path = \"../../dataRea/stats.parquet\"\n",
    "    df_stats = pd.read_parquet(df_stats_path)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        df_final = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        for variableStr in listeVar:\n",
    "            \n",
    "            dfPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Complet\" + \".parquet\"\n",
    "            df = pd.read_parquet(dfPath)\n",
    "\n",
    "            if variableStr == \"Dialyse\":\n",
    "                df_final[variableStr] = df\n",
    "            else:\n",
    "                mean = df_stats[variableStr][0]\n",
    "                sd = df_stats[variableStr][1]\n",
    "                # mini = df_stats[variableStr][2]\n",
    "                # maxi = df_stats[variableStr][3]\n",
    "    \n",
    "                if variableStr == \"Diurese\":\n",
    "                    df_final[variableStr] = (df.iloc[:, 0]/1000 - mean) / sd\n",
    "                else:\n",
    "                    df_final[variableStr] = (df.iloc[:, 0] - mean) / sd\n",
    "                # df_final[variableStr] = (df.iloc[:, 0] - mini) / (maxi - mini)\n",
    "\n",
    "\n",
    "        df_final_Path = finalDataPath + encounterId + \"/dynamic.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(df_final), df_final_Path)\n",
    "\n",
    "\n",
    "def regroupement_mask(dataGroup):\n",
    "\n",
    "    if dataGroup == \"dataECMO\":\n",
    "        dataPath = \"dataECMO/\"\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD\", \"PAM\", \"PAS\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"Compliance\", \"DebitECMO\"]    \n",
    "    elif dataGroup == \"dataRea\":\n",
    "        dataPath = \"dataRea/\"\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD\", \"PAM\", \"PAS\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"Compliance\"]\n",
    "    else:\n",
    "        dataPath = \"../dataMimic/\"\n",
    "        listeVar = [\"HR\", \"SpO2\", \"PAD\", \"PAM\", \"PAS\", \"RR\", \"Temperature\", \"Diurese\", \"SpO2_sur_FiO2\", \"FiO2\", \"Compliance\", \"Dialyse\"]\n",
    "\n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "\n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    finalDataPath = dataPath + \"finalData/\"\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        df_final = pd.DataFrame()\n",
    "        \n",
    "        for variableStr in listeVar:\n",
    "\n",
    "            dfPath = preProcessedDataPath + encounterId + \"/\" + variableStr + \"_Mask\" + \".parquet\"\n",
    "            df = pd.read_parquet(dfPath)\n",
    "            df_final[variableStr] = df\n",
    "\n",
    "        df_final_Path = finalDataPath + encounterId + \"/mask.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(df_final), df_final_Path)\n",
    "\n",
    "\n",
    "def regroupement_static(dataGroup):\n",
    "    \n",
    "    if dataGroup == \"dataECMO\":\n",
    "        dataPath = \"dataECMO/\"\n",
    "    elif dataGroup == \"dataRea\":\n",
    "        dataPath = \"dataRea/\"\n",
    "    else:\n",
    "        dataPath = \"../dataMimic/\"\n",
    "        \n",
    "    patients_df = pd.read_csv(dataPath + \"ventiles.csv\")\n",
    "        \n",
    "    preProcessedDataPath = dataPath + \"preProcessedData/\"\n",
    "    finalDataPath = dataPath + \"finalData/\"\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    for index, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "\n",
    "        encounterId = str(row[\"stay_id\"])\n",
    "\n",
    "        df_final_static = pd.DataFrame()\n",
    "\n",
    "        age = int(patients_df.loc[patients_df[\"stay_id\"]==int(encounterId),\"Age\"].to_numpy()[0])\n",
    "        df_final_static['age'] = [(age - 18) / (93 - 18)]\n",
    "\n",
    "        sexe = str(patients_df.loc[patients_df[\"stay_id\"]==int(encounterId),\"gender\"].to_numpy()[0])\n",
    "        if sexe == \"M\":\n",
    "            df_final_static['sexe'] = [-1]\n",
    "        else:\n",
    "            df_final_static['sexe'] = [1]\n",
    "\n",
    "        mean_IMC = 27.204   #Stats sur Réa Rangueil\n",
    "        sd_IMC = 6.135\n",
    "        min_IMC = 10.84\n",
    "        max_IMC = 65.53\n",
    "        dfPath = preProcessedDataPath + encounterId + \"/IMC\" + \".parquet\"\n",
    "        df = pd.read_parquet(dfPath)\n",
    "        df_final_static['IMC'] = (df.iloc[:, 0] - mean_IMC) / sd_IMC\n",
    "        # df_final_static['IMC'] = (df.iloc[:, 0] - min_IMC) / (max_IMC - min_IMC)\n",
    "\n",
    "\n",
    "        df_final_Path = finalDataPath + encounterId + \"/static.parquet\"\n",
    "        pq.write_table(pa.Table.from_pandas(df_final_static), df_final_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9ed4565-b583-4df4-aa21-a32b24c3649d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4265/4265 [01:01<00:00, 69.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4265/4265 [00:55<00:00, 77.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def gestionDonneesAberrantesFull(dataGroup):\n",
    "\n",
    "    # gestionDonneesAberrantes(dataGroup, \"HR\", 20, 200, 'HR')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"SpO2\", 50, 100, 'SpO2')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PAD_I\", 20, 130, 'PAD_I')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PAD_NI\", 20, 130, 'PAD_NI')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PAM_I\", 30, 200, 'PAM_I')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PAM_NI\", 30, 200, 'PAM_NI')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PAS_I\", 40, 230, 'PAS_I')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PAS_NI\", 40, 230, 'PAS_NI')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"RR\", 5, 50, 'RR')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"Temperature_C\", 32, 41, 'Temperature_C')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"Temperature_F\", 89.6, 105.8, 'Temperature_F')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"Diurese\", 0, 2000,'Diurese')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"Weight\", 30, 300, 'Weight')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"Height\", 120, 230, 'Height')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"FiO2\", 20, 100, 'FiO2')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"Pplat\", 5, 30, 'Pplat')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"VolumeCourant\", 100, 800, 'VolumeCourant')\n",
    "    # gestionDonneesAberrantes(dataGroup, \"PEP\", 2, 22, 'PEP')\n",
    "    \n",
    "    if dataGroup == \"dataECMO\":\n",
    "        gestionDonneesAberrantes(dataGroup, \"DebitECMO\", 0, 8, 'debit')\n",
    "\n",
    "\n",
    "def moyennageFull(dataGroup):\n",
    "\n",
    "    # gestionIMC(dataGroup)\n",
    "    # gestionDiurese(dataGroup, 6)\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"Diurese0\", 60, \"Diurese\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"HR\", 60, \"HR\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"SpO2\", 60, \"SpO2\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAD_I\", 60, \"PAD_I\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAM_I\", 60, \"PAM_I\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAS_I\", 60, \"PAS_I\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"RR\", 60, \"RR\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"Temperature_C\", 60, \"Temperature_C\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"Temperature_F\", 60, \"Temperature_F\")\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAD_NI\", 60, 'PAD_NI')\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAM_NI\", 60, 'PAM_NI')\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAS_NI\", 60, 'PAS_NI')\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"PAD_NI\", 60, 'PAD_NI')\n",
    "    # gestionFiO2(dataGroup, 60)\n",
    "\n",
    "    # moyenne_sur_x_minutes(dataGroup, \"FiO2\", 60, 'FiO2') # Facultatif\n",
    "\n",
    "    if dataGroup == \"dataECMO\":\n",
    "        moyenne_sur_x_minutes(dataGroup, \"DebitECMO\", 60, \"debit\")\n",
    "\n",
    "\n",
    "def gestionValeursManquantesFull(dataGroup):\n",
    "\n",
    "    # gestionValeursManquantes(dataGroup, \"HR\", \"HR\", 85)\n",
    "    # gestionValeursManquantes(dataGroup, \"SpO2\", \"SpO2\", 96)\n",
    "    # gestionValeursManquantesPA(dataGroup, \"PAD\", \"PAD\", 60)\n",
    "    # gestionValeursManquantesPA(dataGroup, \"PAM\", \"PAM\", 80)\n",
    "    # gestionValeursManquantesPA(dataGroup, \"PAS\", \"PAS\", 125)\n",
    "    # gestionValeursManquantes(dataGroup, \"RR\", \"RR\", 22)\n",
    "    # gestionValeursManquantesTemperatures(\"Temperature\", 37)\n",
    "    # gestionValeursManquantes(dataGroup, \"Diurese0\", \"Diurese\", 0.0015, isDiurese=True)\n",
    "    # gestionValeursManquantes(dataGroup, \"SpO2_sur_FiO2\", 'SpO2_sur_FiO2', 2.5)\n",
    "    # gestionValeursManquantes(dataGroup, \"Compliance\", 'Compliance', 40)\n",
    "    # gestionValeursManquantes(dataGroup, \"FiO2\", \"FiO2\", 40) # Facultatif\n",
    "\n",
    "    if dataGroup == \"dataECMO\":\n",
    "        gestionValeursManquantes(dataGroup, \"DebitECMO\", \"debit\", 3)\n",
    "\n",
    "\n",
    "def exportStatsFull(dataGroup):\n",
    "    exportStats(dataGroup)\n",
    "\n",
    "\n",
    "def regroupementFull(dataGroup):\n",
    "    regroupement(dataGroup)\n",
    "    regroupement_mask(dataGroup)\n",
    "    # regroupement_static(dataGroup)\n",
    "\n",
    "\n",
    "# dataGroup = \"dataECMO\"\n",
    "# dataGroup = \"dataRea\"\n",
    "dataGroup = \"dataMimic\"\n",
    "\n",
    "# gestionDonneesAberrantesFull(dataGroup)\n",
    "# moyennageFull(dataGroup)\n",
    "# gestionValeursManquantesFull(dataGroup)\n",
    "# exportStatsFull(dataGroup)\n",
    "regroupementFull(dataGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3c14f4-7488-450d-9eea-a1dad823f3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4265/4265 [00:26<00:00, 162.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4265/4265 [00:20<00:00, 206.99it/s]\n"
     ]
    }
   ],
   "source": [
    "dataGroup = \"dataMimic\"\n",
    "# moyenne_sur_x_minutes(dataGroup, \"PEP\", 60, 'PEP')\n",
    "moyenne_sur_x_minutes(dataGroup, \"VolumeCourant\", 60, 'VolumeCourant')\n",
    "moyenne_sur_x_minutes(dataGroup, \"Pplat\", 60, 'Pplat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a21219-280b-4736-8e3e-725424362e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env0]",
   "language": "python",
   "name": "conda-env-env0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
