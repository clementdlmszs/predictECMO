{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, target, test_size):\n",
    "    nb_samples = len(target)\n",
    "    nb_test = int(test_size * nb_samples)\n",
    "\n",
    "    shuffle = list(range(nb_samples))\n",
    "    random.shuffle(shuffle)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    \n",
    "    nb_0 = 0\n",
    "    nb_1 = 0\n",
    "\n",
    "    for idx in shuffle:\n",
    "        if nb_0 < (nb_test//2) and target[idx]==0:\n",
    "            y_test.append(0)\n",
    "            X_test.append(data[idx])\n",
    "            nb_0 += 1\n",
    "        elif nb_1 < (nb_test//2) and target[idx]==1:\n",
    "            y_test.append(1)\n",
    "            X_test.append(data[idx])\n",
    "            nb_1 += 1\n",
    "        else:\n",
    "            y_train.append(target[idx])\n",
    "            X_train.append(data[idx])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = split_train_test(data, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateData(dataGroup, id_list, window_time):\n",
    "    \n",
    "    if dataGroup == \"dataECMO\":\n",
    "        dataPath = \"../data/\"\n",
    "        patients_df = pd.read_parquet(dataPath + \"patients.parquet\")\n",
    "    else:\n",
    "        dataPath = \"../dataRea/\"\n",
    "        patients_df = pd.read_parquet(dataPath + \"patientsRea.parquet\")\n",
    "\n",
    "    finalDataPath = dataPath + \"finalData/\"\n",
    "\n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for encounterId in tqdm(id_list, total=len(id_list)):\n",
    "        \n",
    "        df_mask = pd.read_parquet(finalDataPath + encounterId + \"/mask.parquet\")\n",
    "        df_dynamic = pd.read_parquet(finalDataPath + encounterId + \"/dynamic.parquet\")\n",
    "        df_static = pd.read_parquet(finalDataPath + encounterId + \"/static.parquet\")\n",
    "        \n",
    "        data_patient = []\n",
    "\n",
    "        df_dynamic_masked = df_dynamic.iloc[:(window_time*24)].mask(df_mask.iloc[:(window_time*24)] == 0)\n",
    "\n",
    "        idx_variables_kept = [0,1,3,4,6,7]\n",
    "        df_dynamic_masked = df_dynamic_masked.iloc[:,idx_variables_kept]\n",
    "        df_dynamic = df_dynamic.iloc[:,idx_variables_kept]\n",
    "\n",
    "        statics = list(df_static.to_numpy()[0])\n",
    "        # CAS OU TOUTE UNE COLONNE EST MASQUEE ?\n",
    "        mean = df_dynamic_masked.mean().tolist()\n",
    "        median = df_dynamic_masked.median().tolist()\n",
    "        maxi = df_dynamic_masked.max().tolist()\n",
    "        mini = df_dynamic_masked.min().tolist()\n",
    "        first = list(df_dynamic.to_numpy()[0,:])\n",
    "        last = list(df_dynamic.to_numpy()[window_time*24-1,:])\n",
    "\n",
    "        data_patient.extend(mean)\n",
    "        # data_patient.extend(median)\n",
    "        data_patient.extend(maxi)\n",
    "        data_patient.extend(mini)\n",
    "        # data_patient.extend(first)\n",
    "        # data_patient.extend(last)\n",
    "        data_patient.extend(statics)\n",
    "\n",
    "        data.append(data_patient)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def prepareDeathList(dataGroup, window_time):\n",
    "    if dataGroup == \"dataECMO\":\n",
    "        dataPath = \"../data/\"\n",
    "        patients_df = pd.read_parquet(dataPath + \"patients.parquet\")\n",
    "    else:\n",
    "        dataPath = \"../dataRea/\"\n",
    "        patients_df = pd.read_parquet(dataPath + \"patientsRea.parquet\")\n",
    "\n",
    "    df_death = pd.read_csv(dataPath + \"delais_deces.csv\")\n",
    "    \n",
    "    nb_patients = len(patients_df)\n",
    "\n",
    "    target = []\n",
    "    id_list = []\n",
    "\n",
    "    for _, row in tqdm(patients_df.iterrows(), total=nb_patients):\n",
    "        encounterId = str(row[\"encounterId\"])\n",
    "        \n",
    "        df_mask = pd.read_parquet(dataPath + \"finalData/\" + encounterId + \"/mask.parquet\")\n",
    "        total_true_values = df_mask.values.sum()\n",
    "        total_values = df_mask.values.size\n",
    "        percentageMissingValues = (total_values-total_true_values)/total_values * 100\n",
    "        \n",
    "        withdrawal_date = pd.Timestamp(row[\"withdrawal_date\"])\n",
    "        installation_date = pd.Timestamp(row[\"installation_date\"])\n",
    "        total_time_hour = (withdrawal_date - installation_date).total_seconds() / 3600 + 4\n",
    "\n",
    "        if total_time_hour >= window_time * 24 and percentageMissingValues < 40:\n",
    "            id_list.append(encounterId)\n",
    "            \n",
    "            delai_sortie_deces = df_death.loc[df_death[\"encounterId\"] == int(encounterId), \"delai_sortie_deces\"].to_numpy()[0]\n",
    "            if delai_sortie_deces <= 3:\n",
    "                target.append(1)\n",
    "            else:\n",
    "                target.append(0)\n",
    "    \n",
    "    return target, id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 392/392 [00:11<00:00, 34.19it/s]\n",
      "100%|██████████| 287/287 [00:24<00:00, 11.69it/s]\n"
     ]
    }
   ],
   "source": [
    "dataGroup = \"dataECMO\"\n",
    "# dataGroup = \"dataRangueil\"\n",
    "\n",
    "window_time_days = 5\n",
    "target, id_list = prepareDeathList(dataGroup, window_time_days)\n",
    "data = aggregateData(dataGroup, id_list, window_time_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.6659910714285714\n"
     ]
    }
   ],
   "source": [
    "aurocs = []\n",
    "for i in range(1000):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_train_test(data, target, test_size=0.2)\n",
    "\n",
    "    # Set parameters for LightGBM\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_error',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 5,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.75,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    # params = {\n",
    "    #     'boosting_type': 'gbdt',\n",
    "    #     'num_leaves': 31,\n",
    "    #     'max_depth': -1,\n",
    "    #     'learning_rate': 0.1,\n",
    "    #     'n_estimators': 100,\n",
    "    #     'subsample_for_bin': 200000,\n",
    "    #     'min_child_samples': 20,\n",
    "    #     'subsample': 1.0,\n",
    "    #     'subsample_freq': 0,\n",
    "    #     'colsample_bytree': 1.0,\n",
    "    #     'reg_alpha': 0.0,\n",
    "    #     'reg_lambda': 0.0,\n",
    "    #     'n_jobs': -1,\n",
    "    #     'importance_type': 'split',\n",
    "    #     'verbose': -1\n",
    "    # }\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    auroc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    aurocs.append(auroc)\n",
    "\n",
    "\n",
    "print(f\"AUROC: {np.mean(aurocs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.6533293697978598\n"
     ]
    }
   ],
   "source": [
    "aurocs = []\n",
    "for i in range(100):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_train_test(data, target, test_size=0.2)\n",
    "\n",
    "    clf = xgb.XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    "    objective='binary:logistic'\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    auroc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    aurocs.append(auroc)\n",
    "\n",
    "\n",
    "print(f\"AUROC: {np.mean(aurocs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.6331747919143875\n"
     ]
    }
   ],
   "source": [
    "aurocs = []\n",
    "for i in range(20):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_train_test(data, target, test_size=0.2)\n",
    "\n",
    "    base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "    clf = BaggingClassifier(estimator=base_classifier, n_estimators=100, random_state=42)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    auroc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    aurocs.append(auroc)\n",
    "\n",
    "\n",
    "print(f\"AUROC: {np.mean(aurocs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 0.6561522108843537\n"
     ]
    }
   ],
   "source": [
    "aurocs = []\n",
    "\n",
    "for i in range(300):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_train_test(data, target, test_size=0.2)\n",
    "\n",
    "    clf = LogisticRegression(solver='sag', penalty='l2', verbose=0, max_iter=1000)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    auroc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    aurocs.append(auroc)\n",
    "\n",
    "print(f\"AUROC: {np.mean(aurocs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
